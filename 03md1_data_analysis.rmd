---
title: "MD1 - CDL data analysis"
author: ""
date: "February 21, 2021"
output:
  pdf_document: default
  html_document: default
---


```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE)

rm(list = ls())

library(tidyverse)
library(psych)
library(summarytools)
library(lme4)
library(car)
library(BayesFactor)
library(bayestestR)

source("./functions/glmm_stability.r")
source("./functions/boot_glmm.r")

load("md1_vienna_glmm_workspace.RData")
```

## Hypothesis
ManyDogs 1 aims to investigate how dogs perceive human pointing gestures. Our specific question is: Do dogs understand and act on human pointing as though it is a social communicative gesture?
While studies of dogs following pointing are numerous, there is ongoing debate in the field of Canine Science about whether dogs perceive pointing gestures as peremptory and follow them much like they would a verbal command, or as socially communicative cues. We will address this question and investigate whether dogs understand and act on pointing as a social communicative gesture by comparing a condition in which pointing is prefaced by ostensive cues (intentional gaze, name calling verbal cues) to a condition in which it is not (gaze avoidance, no verbal cues). 

### Condition predictions
i) We predict that if dogs perceive pointing gestures as commands, as a group they would follow the gesture above chance in both experimental conditions. Moreover, we would expect there to be no significant differences between point-following by dogs in the two experimental conditions. 
ii) We predict that if dogs perceive pointing gestures as socially communicative cues, they would perform significantly better in the ostensive condition than in the non-ostensive condition. 
iii) We predict that in the odor control task that dogs will not differ significantly from the hypothetical chance level of 0.5.

## Analysis

We pre-registered the study design, procedure, predictions, and confirmatory analysis prior to data collection at the Open Science Framework (https://osf.io/gz5pj/). The data and analysis script is available in an associated online repository at https://github.com/ManyDogsProject/manydogs1_vienna.git.  

To evaluate whether the dogs' performance deviated significantly from the hypothetical chance level of 0.5 in the ostensive, non-ostensive, and odor control condition we first aggregated the data across trials for each individual and condition. We then conducted conducted one-sample t-tests to compare the performance against chance. We calculated Bayes factors using the `ttestBF()` function from the _BayesFactor_ package [@Morey.2018].   

To compare the performance between the test conditions (ostensive, non-ostensive) we fitted a Generalised Linear Mixed Model (GLMM) with binomial error distribution and logit link function using the function 'glmer' of the lme4 package [@Bates.2015]. We included the predictor variables condition, order of condition (ostensive first, non-ostensive first), the trial number within condition, sex, age (in years), dogs' trainability score based on the C-BARQ questionnaire [@Hsu.2003]. Additionally, we included the random intercept of subject ID and the random slopes of condition and trial number within subject ID.  

In a secondary, exploratory analysis, we also included pilot data collected prior to the preregistration. We fitted another GLMM only with purebred dogs to account for breed differences in the model. Only breeds with at least 8 individuals in the data set were considered (N = 68; number of breeds: 6), namely Australian Shepherds, Border Collies, Golden Retrievers, Jack Russell / Parson Russell Terriers, Labrador Retrievers, and Rhodesian Ridgebacks. We added the same fixed and random effects as before. Additionally, we also entered breed ID as a random intercept and all random slopes within breed ID.

All covariates were centered and scaled to a standard deviation of 1. The random slope components of the factors were centered (to ensure that the results were not conditional on the choice of the reference category). Confidence intervals for the predictors were derived based on 1000 parametric bootstraps using a function kindly provided by Roger Mundry (based on the `bootMer()` function of the package _lme4_). In order to check for collinearity issues, we determined variance inflation factors (VIF) using the function `vif()` (R package _car_, @Fox.2019). Collinearity was no issue (maximum VIF: 1.02). To evaluate the model stability we dropped one level of the subject ID random effect at a time and compared the model estimates of the resulting models (using a function kindly provided by Roger Mundry). This procedure revealed the models to be stable with respect to the fixed effects.

As inference criterion, we used p-values below .05 (two-tailed) for the one-sample t-tests. For the GLMM, we used likelihood ratio tests (R function `drop1()` with argument 'test' set to "Chisq", @Barr.2013) with p-values smaller than .05 as criterion to make inferences about fixed effects. 

Bayes factors for the models were calculated from Bayesian models using the `brm()` function from the _brms_ package [@R-brms]. We used default, non-informative priors, 12,000 iterations per chain (of which 2,000 were warm-up iterations), and 4 chains for the Bayesian models. We then used the `bayes_factor()` function to compare models, with 10 repetitions using bridge sampling [@R-bridge_sampler]. For the GLMM, Bayes factors represent the evidence for the full model over the full model without the fixed effect under investigation.


## Results  

```{r include = FALSE}
# Read data
prereg.data <- read.csv("data/md1_data_vienna_long.csv") %>%
  filter(preregistered_data=="after_prereg")%>% #only data that were collected after preregistration
  na.exclude() %>%
  droplevels()

summary(prereg.data)
view(dfSummary(prereg.data))
```



```{r include = FALSE}
# Aggregating data
agg.data <- prereg.data  %>%
  group_by(subject_ID, sex, breed, age, condition) %>%
  summarise(mean.resp = mean(response)) %>%
  ungroup()

#demographics:
agg.data%>%filter(condition=="ost")%>%
  summarise(mean.age = mean(age), min.age = min(age), max.age = max(age), sd.age = sd(age), females=sum(sex=="F"), males=sum(sex=="M"))

agg.data%>%filter(condition=="ost")%>% group_by(breed)%>%
  summarise(n.breeds = n())

summary.data <- agg.data %>%
  group_by(condition) %>%
  summarise(mean.resp2 = mean(mean.resp), median.resp = median(mean.resp), sd = sd(mean.resp), se = sd(mean.resp) / sqrt(length(mean.resp)))


summary.data
```

### One-sample t-test to compare against chance level

```{r include=FALSE}

tt.ost <- t.test(agg.data$mean.resp[agg.data$condition == "ost"], mu = 0.5, alternative = "two.sided")
tt.non <- t.test(agg.data$mean.resp[agg.data$condition == "non"], mu = 0.5, alternative = "two.sided")
tt.oc <- t.test(agg.data$mean.resp[agg.data$condition == "odour"], mu = 0.5, alternative = "two.sided")

tt.ost
tt.non
tt.oc
```

```{r include=FALSE}

ttbf.ost <- ttestBF(agg.data$mean.resp[agg.data$condition == "ost"], mu = 0.5, alternative = "two.sided")
ttbf.non <- ttestBF(agg.data$mean.resp[agg.data$condition == "non"], mu = 0.5, alternative = "two.sided")
ttbf.oc <- ttestBF(agg.data$mean.resp[agg.data$condition == "odour"], mu = 0.5, alternative = "two.sided")

extractBF(ttbf.ost)$bf
extractBF(ttbf.non)$bf
extractBF(ttbf.oc)$bf
```
The dogs (N = 61) performed significantly better than expected by chance in the ostensive condition (mean = `r round(tt.ost$estimate, 2)`, 95% CI [`r round(tt.ost$conf.int[1],2)`, `r round(tt.ost$conf.int[2],2)`], *t*(`r tt.ost$parameter`)=`r round(tt.ost$statistic,2)`, *p*=`r round(tt.ost$p.value,3)`, *BF*=`r round(extractBF(ttbf.ost)$bf, 2)`) but not in the non-ostensive condition (mean = `r round(tt.non$estimate, 2)`, 95% CI [`r round(tt.non$conf.int[1],2)`, `r round(tt.non$conf.int[2],2)`], *t*(`r tt.non$parameter`)=`r round(tt.non$statistic,2)`, *p*=`r round(tt.non$p.value,3)`, *BF*=`r round(extractBF(ttbf.non)$bf, 2)`) or the odor control condition (mean = `r round(tt.oc$estimate, 2)`, 95% CI [`r round(tt.oc$conf.int[1],2)`, `r round(tt.oc$conf.int[2],2)`], *t*(`r tt.oc$parameter`)=`r round(tt.oc$statistic,2)`, *p*=`r round(tt.oc$p.value,3)`, *BF*=`r round(extractBF(ttbf.oc)$bf, 2)`). 


### Generalised linear mixed model

```{r include=FALSE}
# centering variables for modeling

model.data <- prereg.data  %>%
  filter(condition == "ost" | condition == "non") %>%
  mutate(
    z.age = as.numeric(scale(age, scale = T, center = T)),
    sex.c = as.numeric(scale(as.numeric(as.factor(sex)), scale = F, center = T)),
    condition.c = as.numeric(scale(as.numeric(as.factor(condition)), scale = F, center = T)),
    condition_order.c = as.numeric(scale(as.numeric(as.factor(condition_order)), scale = F, center = T)),
    z.trial_num = as.numeric(scale(trial_num, scale = T, center = T)),
    z.training_experience = as.numeric(scale(dog_training_experience, scale = T, center = T))
  )

#view(dfSummary(model.data))
```



```{r include=FALSE}
contr <- glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 10000000))

mm1 <- glmer(response ~ condition + condition_order + z.trial_num + sex + z.age + z.training_experience + (condition.c + z.trial_num | subject_ID),
  family = binomial, data = model.data, control = contr
)
```


```{r include=FALSE}
#*Likelihood ratio test*
drop1.mm1<-drop1(mm1, test = "Chisq", control = contr) 
round(drop1.mm1, 3)
```
The dogs were significantly more likely to choose the baited cup in the ostensive condition compared to the non-ostensive condition ($\chi$^2^(`r round(drop1.mm1["condition", "npar"],3)`)=`r round(drop1.mm1["condition", "LRT"],3)`, p = `r round(drop1.mm1["condition", "Pr(Chi)"],3)`). The control predictors order of condition, trial number (within condition), sex, age, or the C-BARQ trainability score had no significant effect on dogs' choices.




```{r include=FALSE}
#*Estimates of the fixed effects*
round(summary(mm1)$coefficients, 3)
```

```{r include=FALSE}
#*Random effects* 
summary(mm1)$varcor
```



```{r eval=FALSE, include=FALSE}
#*Calculating confidence intervals with 1000 bootstraps*
#perform bootstraps for all predictors
mm1.boot.ci <- boot.glmm.pred(model.res = mm1, excl.warnings = T, nboots = 1000, para = T, n.cores="all-1", level = 0.95)
```


```{r include=FALSE}
round(mm1.boot.ci$ci.estimates, 3)
```
Table: Results of GLMM of the dogs' choice performance in Experiment 1  

|                           | Estimate | SE    | 95% CI        ||$\chi$^2^|df| P  |
|---------------------------|----------|-------|--------|-------|-------|----|-------|
| (Intercept)               | 0.122    | 0.128 | -0.134 | 0.372 |       |    |       |
| Condition                 | 0.298    | 0.132 | 0.034  | 0.575 | 5.107 | 1  | 0.024 |
| Order of condition        | 0.057    | 0.133 | -0.216 | 0.324 | 0.185 | 1  | 0.667 |
| Trial number              | -0.100   | 0.066 | -0.227 | 0.032 | 2.322 | 1  | 0.128 |
| Sex                       | -0.084   | 0.137 | -0.361 | 0.184 | 0.371 | 1  | 0.543 |
| Age                       | -0.012   | 0.067 | -0.140 | 0.121 | 0.033 | 1  | 0.855 |
| C-BARQ trainability score | 0.095    | 0.067 | -0.034 | 0.236 | 1.957 | 1  | 0.162 |
Notes: Reference categories: condition: non-ostensive condition; order of condition: non-ostensive condition first; sex: female; covariates trial number, age, and training experienced centered and scaled to a standard deviation of 1. The standard deviations for the contribution of the random effects were 0.099 for the random intercept of subject, 0.159 for the random slope of condition within subject, and 0.063 for the random slope of trial number within subject.

```{r include=FALSE}
### Check assumptions
# check for colliniarity
xx <- lm(response ~ condition + condition_order + z.trial_num + sex + z.age,
  data = model.data
)
vif(xx)
#Collinearity was no issue (maximum variance inflation factor: 1.02)
```

```{r eval=FALSE, include=FALSE}
# Model stability
# One subject at a time excluded to assess the impact of outliers. 

m.stab.b <- glmm.model.stab(model.res = mm1, use = c("subject_ID"))
m.stab.b$detailed$warnings
xx <- as.data.frame(round(m.stab.b$summary[, -1], 3))

png("graphs/mm1_stability_plot.png")
m.stab.plot(round(m.stab.b$summary[, -1], 3))
dev.off()

```

```{r include=FALSE}
m.stab.plot(round(m.stab.b$summary[, -1], 3))
#The model appeared to be stable with respect to the fixed effects (see mm1_stability_plot).
```


```{r eval=FALSE, include=FALSE}
# Calculate CIs for plot
# Model with all predictor variables centered except for condition:
mm1.CI.con <- glmer(response ~ condition + condition_order.c + z.trial_num + sex.c + z.age + z.training_experience + (condition.c + z.trial_num | subject_ID),
  family = binomial, data = model.data, control = contr
)
```

```{r eval=FALSE, include=FALSE}
pred.con.ci=boot.glmm.pred(model.res=mm1.CI.con,  level=0.95, use="condition", n.cores="all-1", para=T)

pred.con.ci$ci.predicted

write.csv(pred.con.ci$ci.predicted, file = "data/mm1_predicted_ci_for_conditionMD1_Vienna.csv")
```


```{r include=FALSE}
#save.image("md1_vienna_glmm_workspace.RData")
```

```{r include=FALSE}
knitr::knit_exit()
```


## all data (including data that was collected prior to preregistration)

### Read data

```{r include = FALSE}
all.data <- read.csv("data/md1_data_vienna_long.csv") %>%
  na.exclude() %>%
  droplevels()

summary(all.data)
#view(dfSummary(all.data))
```

### Aggregating data

```{r include = FALSE}

agg.data.all <- all.data %>%
  group_by(subject_ID, sex, breed, age, condition) %>%
  summarise(mean.resp = mean(response)) %>%
  ungroup()

#demographics:
agg.data.all%>%filter(condition=="ost")%>%
  summarise(mean.age = mean(age), min.age = min(age), max.age = max(age), sd.age = sd(age), females=sum(sex=="F"), males=sum(sex=="M"))

agg.data.all%>%filter(condition=="ost")%>% group_by(breed)%>%
  summarise(n.breeds = n())

summary.data.all <- agg.data.all %>%
  group_by(condition) %>%
  summarise(mean.resp2 = mean(mean.resp), median.resp = median(mean.resp), sd = sd(mean.resp), se = sd(mean.resp) / sqrt(length(mean.resp)))


summary.data.all
```

### One-sample t-test to compare against chance level


```{r}

tt.ost.all <- t.test(agg.data.all$mean.resp[agg.data.all$condition == "ost"], mu = 0.5, alternative = "two.sided")
tt.non.all <- t.test(agg.data.all$mean.resp[agg.data.all$condition == "non"], mu = 0.5, alternative = "two.sided")
tt.oc.all <- t.test(agg.data.all$mean.resp[agg.data.all$condition == "odour"], mu = 0.5, alternative = "two.sided")

tt.ost.all
tt.non.all
tt.oc.all
```
The dogs (N = 91) performed significantly better than expected by chance in the ostensive condition (mean = `r round(tt.ost.all$estimate, 2)`, 95% CI [`r round(tt.ost.all$conf.int[1],2)`, `r round(tt.ost.all$conf.int[2],2)`], *t*(`r tt.ost.all$parameter`)=`r round(tt.ost.all$statistic,2)`, *p*=`r round(tt.ost.all$p.value,3)`) but not in the non-ostensive condition (mean = `r round(tt.non.all$estimate, 2)`, 95% CI [`r round(tt.non.all$conf.int[1],2)`, `r round(tt.non.all$conf.int[2],2)`], *t*(`r tt.non.all$parameter`)=`r round(tt.non.all$statistic,2)`, *p*=`r round(tt.non.all$p.value,3)`) or the odor control condition (mean = `r round(tt.oc.all$estimate, 2)`, 95% CI [`r round(tt.oc.all$conf.int[1],2)`, `r round(tt.oc.all$conf.int[2],2)`], *t*(`r tt.oc.all$parameter`)=`r round(tt.oc.all$statistic,2)`, *p*=`r round(tt.oc.all$p.value,3)`). 

### Generalised linear mixed model

```{r}
# centering variables for modeling

model.data.all <- all.data %>%
  filter(condition == "ost" | condition == "non") %>%
  mutate(
    z.age = as.numeric(scale(age, scale = T, center = T)),
    sex.c = as.numeric(scale(as.numeric(as.factor(sex)), scale = F, center = T)),
    condition.c = as.numeric(scale(as.numeric(as.factor(condition)), scale = F, center = T)),
    condition_order.c = as.numeric(scale(as.numeric(as.factor(condition_order)), scale = F, center = T)),
    z.trial_num = as.numeric(scale(trial_num, scale = T, center = T)),
    z.training_experience = as.numeric(scale(dog_training_experience, scale = T, center = T))
  )

#view(dfSummary(model.data.all))
```



```{r}
contr <- glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 10000000))

mm2 <- glmer(response ~ condition + condition_order + z.trial_num + sex + z.age + z.training_experience + (condition.c + z.trial_num |subject_ID),
  family = binomial, data = model.data.all, control = contr
)
```

*Likelihood ratio test*
```{r}
drop1.mm2<-drop1(mm2, test = "Chisq", control = contr) 
round(drop1.mm2, 3)
```
The dogs were significantly more likely to choose the baited cup in the ostensive condition compared to the non-ostensive condition ($\chi$^2^(`r round(drop1.mm2["condition", "npar"],3)`)=`r round(drop1.mm2["condition", "LRT"],3)`, p = `r round(drop1.mm2["condition", "Pr(Chi)"],3)`). The control predictors order of condition, trial number (within condition), sex, age, or the C-BARQ trainability score had no significant effect on dogs' choices.

*Estimates of the fixed effects*  
```{r}
round(summary(mm2)$coefficients, 3)
```

*Random effects* 
```{r}
summary(mm2)$varcor
```

*Calculating confidence intervals with 1000 bootstraps*
```{r eval=FALSE}
# perform bootstraps for all predictors
boot.res.mm2 <- boot.glmm.pred(model.res = mm2, excl.warnings = T, nboots = 1000, para = T, level = 0.95, n.cores="all-1")
```
```{r}
round(boot.res.mm2$ci.estimates, 3)
```


### Check assumptions
```{r}
# check for colliniarity
xx2 <- lm(response ~ condition + condition_order + z.trial_num + sex + z.age,
  data = model.data
)
vif(xx2)
```

### Model stability
One subject at a time excluded to assess the impact of outliers. 
```{r eval=FALSE}
m.stab.b.mm2 <- glmm.model.stab(model.res = mm2, use = c("subject_ID"))
m.stab.b.mm2$detailed$warnings
xx2 <- as.data.frame(round(m.stab.b$summary[, -1], 3))
png("graphs/mm2_stability_plot.png")
m.stab.plot(round(m.stab.b.mm2$summary[, -1], 3))
dev.off()
```

```{r}
m.stab.plot(round(m.stab.b.mm2$summary[, -1], 3))
```



### Calculate CIs for plot
```{r}
# Model with all predictor variables centered except for condition:
mm2.CI.con <- glmer(response ~ condition + condition_order.c + z.trial_num + sex.c + z.age + z.training_experience + (condition.c + z.trial_num | subject_ID),
  family = binomial, data = model.data, control = contr
)
```

```{r eval=FALSE}
mm2.pred.con.ci=boot.glmm.pred(model.res=mm2.CI.con,  level=0.95, use="condition", n.cores="all-1", para=T)

mm2.pred.con.ci$ci.predicted

write.csv(mm2.pred.con.ci$ci.predicted, file = "data/mm2_predicted_ci_for_condition_MD1_Vienna.csv")
```

```{r}
#save.image("md1_vienna_glmm_workspace.RData")
```


### Breed model

```{r}
# centering variables for modeling

model.data.breed <- all.data %>%
  filter(condition == "ost" | condition == "non") %>%
  filter(breed!="MIX", breed!="Samoyed", breed!="White Swiss Shepherd Dog", breed!="Siberian_Husky")%>% #removing breeds with N<8
  mutate(
    z.age = as.numeric(scale(age, scale = T, center = T)),
    sex.c = as.numeric(scale(as.numeric(as.factor(sex)), scale = F, center = T)),
    condition.c = as.numeric(scale(as.numeric(as.factor(condition)), scale = F, center = T)),
    condition_order.c = as.numeric(scale(as.numeric(as.factor(condition_order)), scale = F, center = T)),
    z.trial_num = as.numeric(scale(trial_num, scale = T, center = T)),
    z.training_experience = as.numeric(scale(dog_training_experience, scale = T, center = T))
  )

#view(dfSummary(model.data.breed))
```
```{r}
contr <- glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 10000000))

mm3 <- glmer(response ~ condition + condition_order + z.trial_num + sex + z.age + z.training_experience + (condition.c + z.trial_num |subject_ID) + (condition.c + condition_order.c + z.trial_num + sex.c + z.age + z.training_experience|breed),
  family = binomial, data = model.data.breed, control = contr
)
```
*Likelihood ratio test*
```{r}
drop1.mm3<-drop1(mm3, test = "Chisq", control = contr) 
round(drop1.mm3, 3)
```

*Estimates of the fixed effects*  
```{r}
round(summary(mm3)$coefficients, 3)
```

*Random effects* 
```{r}
summary(mm3)$varcor
```

*Calculating confidence intervals with 1000 bootstraps*
```{r eval=FALSE}
# perform bootstraps for all predictors
boot.res.mm3 <- boot.glmm.pred(model.res = mm3, excl.warnings = T, nboots = 1000, para = T, level = 0.95, n.cores="all-1")
```

```{r}
round(boot.res.mm3$ci.estimates, 3)
```

*Model table*
```{r}
pred.names = tibble(effect=c("(Intercept)", "Condition", "Order of condition", "Trial number", "Sex", "Age", "C-BARQ trainability score"))

model_table.mm3 <- bind_cols(as.data.frame(summary(mm3)$coefficients),
                         drop1.mm3,
                         boot.res.mm3$ci.estimates,
                         pred.names) %>% #,model_bfs
  select(effect, Estimate, SE = `Std. Error`, LowerCI = X2.5., UpperCI = X97.5., Chi2 = LRT, df = npar, p = `Pr(Chi)`) %>%#, bf
  mutate(across(.cols = c(p), ~ round(.x, 3))) %>% #bf
  mutate(across(.cols = c(Estimate:Chi2), ~ round(.x, 2))) %>% 
  mutate(across(Chi2:p, ~replace_na(.x, ""))) %>% #:bf
  remove_rownames()
```
```{r}

model_table.mm3.re <-as.data.frame(VarCorr(mm3))%>%
  filter(is.na(var2))%>%
  select("Random.intercept" = grp, "Random.slope" = var1, "SD" = sdcor)%>%
  mutate(across(.cols = c(SD), ~ round(.x, 2)))%>%
  mutate(Random.intercept=fct_recode(Random.intercept,  "Subject"="subject_ID", "Breed"="breed"), Random.slope=fct_recode(Random.slope,  "Condition"="condition.c", "Trial number"="z.trial_num",  "Order of conditions"="condition_order.c",  "Sex"="sex.c",  "Age"="z.age",  "C-BARQ trainability score"="z.training_experience"))
```
We then fitted a second model only with purebred dogs and including breed as a random effect (as well as all possible random slopes within breed). This model confirmed the results of the first model: dogs of the six included breeds were significantly more likely to choose the baited cup in the ostensive condition compared to the non-ostensive condition ($\chi$^2^(`r round(drop1.mm3["condition", "npar"],3)`)=`r round(drop1.mm3["condition", "LRT"],3)`, p = `r round(drop1.mm3["condition", "Pr(Chi)"],3)`). The control predictors order of condition, trial number (within condition), sex, age, or the C-BARQ trainability score had no significant effect on dogs' choices. The standard deviations for the contribution of the random effects of breed were small in comparison to the standard deviations of the random effects within subject ID. 

### Check assumptions
```{r}
# check for colliniarity
xx3 <- lm(response ~ condition + condition_order + z.trial_num + sex + z.age,
  data = model.data.breed
)
vif(xx3)
```
### Model stability
One subject at a time excluded to assess the impact of outliers. 
```{r eval=FALSE}
m.stab.b.mm3 <- glmm.model.stab(model.res = mm3, use = c("subject_ID", "breed"))
m.stab.b.mm3$detailed$warnings
xx2 <- as.data.frame(round(m.stab.b$summary[, -1], 3))
png("graphs/mm3_stability_plot.png")
m.stab.plot(round(m.stab.b.mm3$summary[, -1], 3))
dev.off()
```

```{r}
m.stab.plot(round(m.stab.b.mm3$summary[, -1], 3))
```


